{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.nddata.utils import Cutout2D\n",
    "from esutil import wcsutil\n",
    "from astropy.io import fits\n",
    "from astropy import table\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.visualization import (ZScaleInterval, ImageNormalize)\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_image = fits.open(\"/home/eyvorch9/projects/rrg-kyi/astro/cfis/W3/CFIS.264.282.r.fits\", memmap=True)\n",
    "r_header = r_image[0].header\n",
    "r_weights = fits.open(\"/home/eyvorch9/projects/rrg-kyi/astro/cfis/W3/CFIS.264.282.r.weight.fits.fz\", memmap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = wcsutil.WCS(r_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_cat = table.Table.read(\"/home/eyvorch9/projects/rrg-kyi/astro/cfis/W3/CFIS.264.282.r.cat\", format=\"ascii.sextractor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = [] # Normalized cutouts\n",
    "weights = []\n",
    "for (ra, dec) in zip(image_cat[\"ALPHA_J2000\"], image_cat[\"DELTA_J2000\"]): # Centers of sources\n",
    "    (x, y) = w.sky2image(ra, dec)\n",
    "    cutout = Cutout2D(r_image[0].data, (x, y), 64, mode=\"partial\", fill_value=0).data\n",
    "    weight_cutout = Cutout2D(r_weights[1].data, (x, y), 64, mode=\"partial\", fill_value=0).data\n",
    "    sources.append((cutout - np.min(cutout)) / (np.max(cutout) - np.min(cutout)))\n",
    "    weights.append((weight_cutout - np.min(weight_cutout)) / (np.max(cutout) - np.min(cutout)))\n",
    "sources = np.array(sources)\n",
    "sources = sources.reshape(*sources.shape, 1)\n",
    "weights = np.array(weights)\n",
    "weights = weights.reshape(*weights.shape, 1)\n",
    "r_image.close()\n",
    "r_weights.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = int(0.8*len(sources))\n",
    "sources_train = sources[:threshold]\n",
    "sources_test = sources[threshold:]\n",
    "weights_train = sources[:threshold]\n",
    "weights_test = sources[threshold:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_autoencoder1(shape):\n",
    "    input_img = keras.Input(shape=shape)\n",
    "    x = keras.layers.Conv2D(16, kernel_size=3, activation='relu', padding='same')(input_img)\n",
    "    x = keras.layers.MaxPooling2D((2,2), padding='same')(x)\n",
    "    x = keras.layers.Conv2D(32, kernel_size=3, activation='relu', padding='same')(x)\n",
    "    x = keras.layers.MaxPooling2D((2,2), padding='same')(x)\n",
    "    x = keras.layers.Flatten()(x)\n",
    "    x = keras.layers.Dense(128)(x)\n",
    "    encoded = keras.layers.Dense(1024)(x)\n",
    "    \n",
    "    x = keras.layers.Reshape((16,16,4))(encoded)\n",
    "    x = keras.layers.UpSampling2D((2,2))(x)\n",
    "    x = keras.layers.Conv2DTranspose(32, kernel_size=3, activation='relu', padding='same')(x)\n",
    "    x = keras.layers.UpSampling2D((2,2))(x)\n",
    "    x = keras.layers.Conv2DTranspose(16, kernel_size=3, activation='relu', padding='same')(x)\n",
    "    decoded = keras.layers.Conv2D(1, (3,3), activation='linear', padding='same')(x)\n",
    "    \n",
    "    return keras.Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder1 = create_autoencoder1((sources.shape[1], sources.shape[2], 1))\n",
    "#opt = keras.optimizers.Adam(learning_rate=0.005)\n",
    "autoencoder1.compile(optimizer=\"adam\", loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history1 = autoencoder1.fit(sources_train, sources_train, batch_size=128, epochs=50, validation_split=0.2, sample_weight=np.sqrt(weights_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_curves(history):\n",
    "    plt.plot(history.history[\"loss\"], color=\"g\", label=\"Training\")\n",
    "    plt.plot(history.history[\"val_loss\"], color=\"b\", label=\"Validation\")\n",
    "    plt.title(\"Loss Curves for Training/Validation Sets\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(history1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs1 = autoencoder1.predict(sources_test[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images):\n",
    "    fig, axes = plt.subplots(3,3, figsize=(8,8))\n",
    "    i = 0\n",
    "    for row in range(3):\n",
    "        for col in range(3):\n",
    "            norm = ImageNormalize(images[i], interval=ZScaleInterval())\n",
    "            axes[row][col].imshow(images[i], norm=norm)\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(sources_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(decoded_imgs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_autoencoder2(shape):\n",
    "    input_img = keras.Input(shape=shape)\n",
    "    x = keras.layers.Conv2D(8, kernel_size=3, activation='relu', padding='same')(input_img)\n",
    "    x = keras.layers.MaxPooling2D((2,2), padding='same')(x)\n",
    "    encoded = keras.layers.Conv2D(16, kernel_size=3, activation='relu', padding='same')(x)\n",
    "\n",
    "    x = keras.layers.Conv2DTranspose(16, kernel_size=3, activation='relu', padding='same')(encoded)\n",
    "    x = keras.layers.UpSampling2D((2,2))(x)\n",
    "    x = keras.layers.Conv2DTranspose(8, kernel_size=3, activation='relu', padding='same')(x)\n",
    "    decoded = keras.layers.Conv2D(1, (3,3), activation='linear', padding='same')(x)\n",
    "    \n",
    "    return keras.Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder2 = create_autoencoder2((sources.shape[1], sources.shape[2], 1))\n",
    "#opt = keras.optimizers.Adam(learning_rate=0.005)\n",
    "autoencoder2.compile(optimizer=\"adam\", loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history2 = autoencoder2.fit(sources_train, sources_train, batch_size=128, epochs=50, validation_split=0.2, sample_weight=np.sqrt(weights_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(history2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs2 = autoencoder2.predict(sources_test[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(sources_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(decoded_imgs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
