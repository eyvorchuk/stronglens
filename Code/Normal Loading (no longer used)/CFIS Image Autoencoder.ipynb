{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.nddata.utils import Cutout2D\n",
    "from astropy.io import fits\n",
    "import fitsio\n",
    "from astropy import table\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.visualization import (ZScaleInterval, ImageNormalize)\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Cut out 64x64 Patches from Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_image = fitsio.read(\"/home/eyvorch9/projects/rrg-kyi/astro/cfis/W3/PS1.262.284.z.fits\")\n",
    "z_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_weights = fitsio.read(\"/home/eyvorch9/projects/rrg-kyi/astro/cfis/W3/PS1.262.284.z.wt.fits\")\n",
    "z_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = fits.open(\"/home/eyvorch9/projects/rrg-kyi/astro/cfis/W3/PS1.262.284.g.fits\")\n",
    "print(img.info())\n",
    "img.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.where(np.isnan(z_image))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_image = np.where(np.isnan(z_image), 0, z_image)\n",
    "len(np.where(np.isnan(z_image))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_image = fitsio.read(\"/home/eyvorch9/projects/rrg-kyi/astro/cfis/W3/CFIS.264.282.r.fits\")\n",
    "len(np.where(np.isnan(r_image))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(z_image, cmap='gray')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = ImageNormalize(z_image, interval=ZScaleInterval())\n",
    "plt.imshow(z_image,norm=norm)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_cat = table.Table.read(\"/home/eyvorch9/projects/rrg-kyi/astro/cfis/W3/CFIS.264.282.r.cat\", format=\"ascii.sextractor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 64x64 patches of sources\n",
    "sources = []\n",
    "for (x, y) in zip(image_cat[\"X_IMAGE\"], image_cat[\"Y_IMAGE\"]): # Centers of sources\n",
    "    sources.append(Cutout2D(r_image, (x, y), 64, mode=\"partial\", fill_value=0).data)\n",
    "sources = np.array(sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot first 9 sources\n",
    "fig, axes = plt.subplots(3,3, figsize=(8,8))\n",
    "i = 0\n",
    "for row in range(3):\n",
    "    for col in range(3):\n",
    "        axes[row][col].imshow(sources[i])\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources[7][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot first 9 sources\n",
    "fig, axes = plt.subplots(3,3, figsize=(8,8))\n",
    "i = 0\n",
    "for row in range(3):\n",
    "    for col in range(3):\n",
    "        norm = ImageNormalize(sources[i], interval=ZScaleInterval())\n",
    "        axes[row][col].imshow(sources[i], norm=norm)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Get Cutouts from CFIS Tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run make_cutouts.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_image = fits.open(\"/home/eyvorch9/projects/rrg-kyi/astro/cfis/W3/CFIS.264.282.r.weight.fits.fz\")\n",
    "weight_image.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"/home/eyvorch9/projects/rrg-kyi/astro/cfis/W3/\"\n",
    "tiles = sorted(glob.glob(image_dir + \"CFIS.*.r.fits\"))\n",
    "weights = sorted(glob.glob(image_dir + \"CFIS.*.r.weight*\"))\n",
    "cats = sorted(glob.glob(image_dir + \"CFIS.*.r.cat\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tiles))\n",
    "print(len(weights))\n",
    "print(len(cats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources_cfis = []\n",
    "sources_norm_keras = []\n",
    "size = 64\n",
    "for (t, w, c) in zip(tiles[:3], weights[:3], cats[:3]):\n",
    "    image = fits.open(t)\n",
    "    #weight = fits.open(w)\n",
    "    image_data = image[0].data\n",
    "    #weight_data = weight[1].data\n",
    "    image.close()\n",
    "    #weight.close()\n",
    "    image_cat = table.Table.read(c, format=\"ascii.sextractor\")\n",
    "    for (x, y) in zip(image_cat[\"X_IMAGE\"], image_cat[\"Y_IMAGE\"]):\n",
    "        cutout = Cutout2D(image_data, (x, y), size, mode=\"partial\", fill_value=0).data\n",
    "        sources_cfis.append(cutout)\n",
    "        sources_norm_keras.append(keras.utils.normalize(cutout))\n",
    "        #sources_cfis.append(Cutout2D(weight_data, (x, y), size, mode=\"partial\", fill_value=0).data)\n",
    "sources_cfis = np.array(sources_cfis)\n",
    "sources_cfis = sources_cfis.reshape(*sources_cfis.shape, 1)\n",
    "sources_norm_keras = np.array(sources_norm_keras)\n",
    "sources_norm_keras = sources_norm_keras.reshape(*sources_norm_keras.shape, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(sources_cfis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sources_cfis[np.isnan(sources_cfis)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3,3, figsize=(8,8))\n",
    "i = 10000\n",
    "for row in range(3):\n",
    "    for col in range(3):\n",
    "        norm = ImageNormalize(sources_cfis[i], interval=ZScaleInterval())\n",
    "        axes[row][col].imshow(sources_cfis[i], norm=norm)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data between 0 and 1\n",
    "sources_norm_01 = (sources_cfis - np.min(sources_cfis)) / (np.max(sources_cfis) - np.min(sources_cfis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3,3, figsize=(8,8))\n",
    "i = 10000\n",
    "for row in range(3):\n",
    "    for col in range(3):\n",
    "        norm = ImageNormalize(sources_norm_01[i], interval=ZScaleInterval())\n",
    "        axes[row][col].imshow(sources_norm_01[i], norm=norm)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3,3, figsize=(8,8))\n",
    "i = 10000\n",
    "for row in range(3):\n",
    "    for col in range(3):\n",
    "        norm = ImageNormalize(sources_norm_keras[i], interval=ZScaleInterval())\n",
    "        axes[row][col].imshow(sources_norm_keras[i], norm=norm)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Get Cutouts from Multiple Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_weights_file = fits.open(\"/home/eyvorch9/projects/rrg-kyi/astro/cfis/W3/PS1.262.284.g.wt.fits\")\n",
    "g_weights_file.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_weights_file = fits.open(\"/home/eyvorch9/projects/rrg-kyi/astro/cfis/W3/CFIS.262.284.r.weight.fits.fz\")\n",
    "r_weights_file.info()\n",
    "r_weights_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_weights_data = g_weights_file[0].data\n",
    "g_weights_data\n",
    "g_weights_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(g_weights_data, cmap='gray')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = ImageNormalize(g_weights_data, interval=ZScaleInterval())\n",
    "plt.imshow(g_weights_data,norm=norm)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_fits = sorted(glob.glob(image_dir + \"PS1.*.g.fits\"))\n",
    "g_weights = sorted(glob.glob(image_dir + \"PS1.*.g.wt.fits\"))\n",
    "i_fits = sorted(glob.glob(image_dir + \"PS1.*.i.fits\"))\n",
    "i_weights = sorted(glob.glob(image_dir + \"PS1.*.i.wt.fits\"))\n",
    "r_fits = tiles\n",
    "r_weights = weights\n",
    "z_fits = sorted(glob.glob(image_dir + \"PS1.*.z.fits\"))\n",
    "z_weights = sorted(glob.glob(image_dir + \"PS1.*.z.wt.fits\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(g_fits))\n",
    "print(len(g_weights))\n",
    "print(len(i_fits))\n",
    "print(len(i_weights))\n",
    "print(len(r_fits))\n",
    "print(len(r_weights))\n",
    "print(len(z_fits))\n",
    "print(len(z_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only use tiles with all four channels\n",
    "\n",
    "PS1 = sorted(glob.glob(image_dir + \"PS1.*\"))\n",
    "start = len(image_dir + \"PS1.\")\n",
    "ra_dec = []\n",
    "for file in PS1:\n",
    "    ra_dec_str = file[start:start+7]\n",
    "    if not ra_dec_str in ra_dec:\n",
    "        ra_dec.append(ra_dec_str)\n",
    "\n",
    "g_fits = []\n",
    "g_weights = []\n",
    "i_fits = []\n",
    "i_weights = []\n",
    "r_fits = []\n",
    "r_weights = []\n",
    "z_fits = []\n",
    "z_weights = []\n",
    "cats = []\n",
    "\n",
    "for ra_dec_str in ra_dec:\n",
    "    try:\n",
    "        g_fits_file = open(image_dir + \"PS1.\" + ra_dec_str + \".g.fits\", \"r\")\n",
    "        g_weights_file = open(image_dir + \"PS1.\" + ra_dec_str + \".g.wt.fits\", \"r\")\n",
    "        i_fits_file = open(image_dir + \"PS1.\" + ra_dec_str + \".i.fits\", \"r\")\n",
    "        i_weights_file = open(image_dir + \"PS1.\" + ra_dec_str + \".i.wt.fits\", \"r\")\n",
    "        r_fits_file = open(image_dir + \"CFIS.\" + ra_dec_str + \".r.fits\", \"r\")\n",
    "        r_weights_file = open(image_dir + \"CFIS.\" + ra_dec_str + \".r.weight.fits.fz\", \"r\")\n",
    "        z_fits_file = open(image_dir + \"PS1.\" + ra_dec_str + \".z.fits\", \"r\")\n",
    "        z_weights_file = open(image_dir + \"PS1.\" + ra_dec_str + \".z.wt.fits\", \"r\")\n",
    "        cat_file = open(image_dir + \"CFIS.\" + ra_dec_str + \".r.cat\", \"r\")\n",
    "        \n",
    "        # All files exist\n",
    "        g_fits.append(g_fits_file.name)\n",
    "        g_weights.append(g_weights_file.name)\n",
    "        i_fits.append(i_fits_file.name)\n",
    "        i_weights.append(i_weights_file.name)\n",
    "        r_fits.append(r_fits_file.name)\n",
    "        r_weights.append(r_weights_file.name)\n",
    "        z_fits.append(z_fits_file.name)\n",
    "        z_weights.append(z_weights_file.name)\n",
    "        cats.append(cat_file.name)\n",
    "        \n",
    "        g_fits_file.close()\n",
    "        g_weights_file.close()\n",
    "        i_fits_file.close()\n",
    "        i_weights_file.close()\n",
    "        r_fits_file.close()\n",
    "        r_weights_file.close()\n",
    "        z_fits_file.close()\n",
    "        z_weights_file.close()\n",
    "        cat_file.close()\n",
    "    except FileNotFoundError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(g_fits))\n",
    "print(len(g_weights))\n",
    "print(len(i_fits))\n",
    "print(len(i_weights))\n",
    "print(len(r_fits))\n",
    "print(len(r_weights))\n",
    "print(len(z_fits))\n",
    "print(len(z_weights))\n",
    "print(len(cats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cutouts = 0\n",
    "for i in range(len(cats)):\n",
    "    cat = table.Table.read(cats[i], format=\"ascii.sextractor\")\n",
    "    n_cutouts += 2 * len(cat) # fits/weights files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of cutouts: \" + str(n_cutouts))\n",
    "print(\"Tensor size: \" + str(n_cutouts*size*size*4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only use 30000 cutouts to reduce tensor size\n",
    "sources_multi = np.zeros((30000, size, size, 4)) # Order of channels is r,g,i,z\n",
    "n = 0\n",
    "for i in range(1):\n",
    "    r_fits_file = fits.open(r_fits[i])\n",
    "    #r_weights_file = fits.open(r_weights[i])\n",
    "    g_fits_file = fits.open(g_fits[i])\n",
    "    #g_weights_file = fits.open(g_weights[i])\n",
    "    i_fits_file = fits.open(i_fits[i])\n",
    "    #i_weights_file = fits.open(i_weights[i])\n",
    "    z_fits_file = fits.open(z_fits[i])\n",
    "    #z_weights_file = fits.open(z_weights[i])\n",
    "    \n",
    "    r_fits_data = r_fits_file[0].data\n",
    "    #r_weights_data = r_weights_file[1].data\n",
    "    g_fits_data = g_fits_file[0].data\n",
    "    #g_weights_data = g_weights_file[0].data\n",
    "    i_fits_data = i_fits_file[0].data\n",
    "    #i_weights_data = i_weights_file[0].data\n",
    "    z_fits_data = z_fits_file[0].data\n",
    "    #z_weights_data = z_weights_file[0].data\n",
    "    \n",
    "    r_fits_file.close()\n",
    "    #r_weights_file.close()\n",
    "    g_fits_file.close()\n",
    "    #g_weights_file.close()\n",
    "    i_fits_file.close()\n",
    "    #i_weights_file.close()\n",
    "    z_fits_file.close()\n",
    "    #z_weights_file.close()\n",
    "    \n",
    "    cat = table.Table.read(cats[i], format=\"ascii.sextractor\")\n",
    "    for (x, y) in zip(cat[\"X_IMAGE\"], cat[\"Y_IMAGE\"]):\n",
    "        sources_multi[n,:,:,0] = Cutout2D(r_fits_data, (x, y), size, mode=\"partial\", fill_value=0).data\n",
    "        #sources[n+1,:,:,0] = Cutout2D(r_weights_data, (x, y), size, mode=\"partial\", fill_value=0).data\n",
    "        sources_multi[n,:,:,1] = Cutout2D(g_fits_data, (x, y), size, mode=\"partial\", fill_value=0).data\n",
    "        #sources[n+1,:,:,1] = Cutout2D(g_weights_data, (x, y), size, mode=\"partial\", fill_value=0).data\n",
    "        sources_multi[n,:,:,2] = Cutout2D(i_fits_data, (x, y), size, mode=\"partial\", fill_value=0).data\n",
    "        #sources[n+1,:,:,2] = Cutout2D(i_weights_data, (x, y), size, mode=\"partial\", fill_value=0).data\n",
    "        sources_multi[n,:,:,3] = Cutout2D(z_fits_data, (x, y), size, mode=\"partial\", fill_value=0).data\n",
    "        #sources[n+1,:,:,3] = Cutout2D(z_weights_data, (x, y), size, mode=\"partial\", fill_value=0).data\n",
    "        n += 1\n",
    "        if n == 30000:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources_multi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "30000*32*32*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_fits_file = fits.open(r_fits[0])\n",
    "r_fits_file.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_fits_data = r_fits_file[0].data\n",
    "r_fits_file.close()\n",
    "r_fits_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_fits_file = fits.open(\"/home/eyvorch9/projects/rrg-kyi/astro/cfis/W3/PS1.262.284.g.fits\")\n",
    "g_fits_data = g_fits_file[0].data\n",
    "g_fits_file.close()\n",
    "g_fits_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_fits_file = fits.open(\"/home/eyvorch9/projects/rrg-kyi/astro/cfis/W3/PS1.262.284.g.fits\")\n",
    "g_fits_file.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_fits_file = fits.open(i_fits[0])\n",
    "i_fits_data = i_fits_file[0].data\n",
    "i_fits_file.close()\n",
    "sum(np.isnan(i_fits_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_fits_file = fits.open(z_fits[0])\n",
    "z_fits_data = z_fits_file[0].data\n",
    "z_fits_file.close()\n",
    "z_fits_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Build Autoencoder for MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_train = x_train.reshape(*x_train.shape, 1)\n",
    "x_test = x_test.astype(\"float32\") / 255.0\n",
    "x_test = x_test.reshape(*x_test.shape, 1)\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(keras.Model):\n",
    "    def __init__(self, shape):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = keras.Sequential([\n",
    "            keras.layers.Input(shape=shape),\n",
    "            keras.layers.Conv2D(8, kernel_size=3, activation='relu', padding='same'),\n",
    "            keras.layers.MaxPooling2D(),\n",
    "            keras.layers.Conv2D(4, kernel_size=3, activation='relu', padding='same')])\n",
    "        \n",
    "        self.decoder = keras.Sequential([\n",
    "            keras.layers.Conv2DTranspose(4, kernel_size=3, activation='relu', padding='same'),\n",
    "            keras.layers.UpSampling2D((2,2)),\n",
    "            keras.layers.Conv2DTranspose(8, kernel_size=3, activation='relu', padding='same'),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Conv2D(1, (3,3), activation='linear', padding='same')])\n",
    "\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(keras.Model):\n",
    "    def __init__(self, shape):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = keras.Sequential([\n",
    "            keras.layers.InputLayer(shape),\n",
    "            keras.layers.Flatten(),\n",
    "            keras.layers.Dense(1000)])\n",
    "\n",
    "        self.decoder = keras.Sequential([\n",
    "            keras.layers.InputLayer(1000,),\n",
    "            keras.layers.Dense(np.prod(shape)),\n",
    "            keras.layers.Reshape(shape)])\n",
    "\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_autoencoder(shape):\n",
    "    input_img = keras.Input(shape=shape)\n",
    "    x = keras.layers.Conv2D(8, kernel_size=3, activation='relu', padding='same')(input_img)\n",
    "    x = keras.layers.MaxPooling2D((2,2), padding='same')(x)\n",
    "    encoded = keras.layers.Conv2D(16, kernel_size=3, activation='relu', padding='same')(x)\n",
    "\n",
    "    x = keras.layers.Conv2DTranspose(16, kernel_size=3, activation='relu', padding='same')(encoded)\n",
    "    x = keras.layers.UpSampling2D((2,2))(x)\n",
    "    x = keras.layers.Conv2DTranspose(8, kernel_size=3, activation='relu', padding='same')(x)\n",
    "    decoded = keras.layers.Conv2D(1, (3,3), activation='linear', padding='same')(x)\n",
    "    \n",
    "    return keras.Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = create_autoencoder((x_train.shape[1], x_train.shape[2], 1))\n",
    "autoencoder.compile(optimizer='adam', loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#log_dir = \"logs/fit/MNIST\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "#tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "autoencoder.fit(x_train, x_train, epochs=5, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs = autoencoder.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare original images to reconstructed images\n",
    "fig, axes = plt.subplots(3,3, figsize=(8,8))\n",
    "i = 0\n",
    "for row in range(3):\n",
    "    for col in range(3):\n",
    "        axes[row][col].imshow(x_test[i])\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3,3, figsize=(8,8))\n",
    "i = 0\n",
    "for row in range(3):\n",
    "    for col in range(3):\n",
    "        axes[row][col].imshow(decoded_imgs[i])\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate original digit from noisy image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_gaussian(x, amp=1):\n",
    "    x_gauss = np.copy(x)\n",
    "    for i in range(len(x)):\n",
    "        img = np.copy(x_gauss[i])\n",
    "        noise = amp*np.random.random((x.shape[1], x.shape[2]))\n",
    "        noise = noise.reshape(*noise.shape, 1)\n",
    "        noisy_image = noise + img\n",
    "        # Renormalize pixel values from 0 to 1\n",
    "        noisy_image = keras.utils.normalize(noisy_image, axis=0)\n",
    "        x_gauss[i] = noisy_image\n",
    "    return x_gauss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_blob(x):\n",
    "    x_blob = np.copy(x)\n",
    "    \n",
    "    lims = [2, x[0].shape[0] - 3] # For limits of center of blob\n",
    "    for i in range(len(x)):\n",
    "        # Place blob with resolution 5x5 onto image\n",
    "        img = np.copy(x[i])\n",
    "        center_x = np.random.randint(low=lims[0], high=lims[1] + 1)\n",
    "        center_y = np.random.randint(low=lims[0], high=lims[1] + 1)\n",
    "        \n",
    "        # Produce standard Gaussian blob and place on image\n",
    "        mux = 0\n",
    "        muy = 0\n",
    "        sigmax = 1\n",
    "        sigmay = 1\n",
    "        blob_size = 5\n",
    "        x_gauss = np.linspace(-1, 1, blob_size)\n",
    "        y_gauss = np.linspace(-1, 1, blob_size)\n",
    "        x_gauss, y_gauss = np.meshgrid(x_gauss, y_gauss)\n",
    "        blob = np.exp(-((x_gauss-mux)**2/(2*sigmax**2) + (y_gauss-muy)**2/(2*sigmay**2)))\n",
    "        blob = blob.reshape(*blob.shape, 1)\n",
    "        img[center_x - 2:center_x + 3,center_y - 2:center_y + 3] = blob\n",
    "        x_blob[i] = img\n",
    "        \n",
    "    return x_blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_blob = add_blob(x_train)\n",
    "x_test_blob = add_blob(x_test)\n",
    "x_train_complex = add_gaussian(x_train_blob)\n",
    "x_test_complex = add_gaussian(x_test_blob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_complex = Autoencoder((x_train.shape[1], x_train.shape[2], 1))\n",
    "autoencoder_complex.compile(optimizer='adam', loss=keras.losses.MeanSquaredError())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/fit/MNIST_Complex\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "autoencoder_complex.fit(x_train_complex, x_train, epochs=25, validation_split=0.2, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs_complex = autoencoder_complex.encoder(x_test).numpy()\n",
    "decoded_imgs_complex = autoencoder_complex.decoder(encoded_imgs_complex).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3,3, figsize=(8,8))\n",
    "i = 0\n",
    "for row in range(3):\n",
    "    for col in range(3):\n",
    "        axes[row][col].imshow(x_test[i])\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3,3, figsize=(8,8))\n",
    "i = 0\n",
    "for row in range(3):\n",
    "    for col in range(3):\n",
    "        axes[row][col].imshow(x_test_complex[i])\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3,3, figsize=(8,8))\n",
    "i = 0\n",
    "for row in range(3):\n",
    "    for col in range(3):\n",
    "        axes[row][col].imshow(decoded_imgs_complex[i])\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Build Autoencoder for CFIS Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First for single channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 80% cutouts for training and remaining for testing\n",
    "threshold = int(0.8*len(sources_cfis))\n",
    "sources_train = sources_cfis[:threshold]\n",
    "sources_test = sources_cfis[threshold:]\n",
    "sources_train_01 = sources_norm_01[:threshold]\n",
    "sources_test_01 = sources_norm_01[threshold:]\n",
    "sources_train_keras = sources_norm_keras[:threshold]\n",
    "sources_test_keras = sources_norm_keras[threshold:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(sources_train_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_cfis_01 = create_autoencoder((sources_cfis.shape[1], sources_cfis.shape[2], 1))\n",
    "autoencoder_cfis_01.compile(optimizer=\"adam\", loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_cfis_keras = Autoencoder((sources_cfis.shape[1], sources_cfis.shape[2], 1))\n",
    "autoencoder_cfis_keras.compile(optimizer='adam', loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_cfis_01.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#log_dir = \"logs/fit/CFIS\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "#tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "history_01 = autoencoder_cfis_01.fit(sources_train_01, sources_train_01, epochs=300, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_keras = autoencoder_cfis_keras.fit(sources_train_keras, sources_train_keras, epochs=100, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_curves(history):\n",
    "    plt.plot(history.history[\"loss\"], color=\"g\", label=\"Training\")\n",
    "    plt.plot(history.history[\"val_loss\"], color=\"b\", label=\"Validation\")\n",
    "    plt.title(\"Loss Curves for Training/Validation Sets\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(history_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(history_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs_01 = autoencoder_cfis_01.predict(sources_test_01[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs_keras = autoencoder_cfis_keras.encoder(sources_test_keras[:100])\n",
    "decoded_imgs_keras = autoencoder_cfis_keras.decoder(encoded_imgs_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(sources_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3,3, figsize=(8,8))\n",
    "i = 0\n",
    "for row in range(3):\n",
    "    for col in range(3):\n",
    "        norm = ImageNormalize(sources_test[i], interval=ZScaleInterval())\n",
    "        axes[row][col].imshow(sources_test[i])\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3,3, figsize=(8,8))\n",
    "i = 0\n",
    "for row in range(3):\n",
    "    for col in range(3):\n",
    "        norm = ImageNormalize(sources_test_01[i], interval=ZScaleInterval())\n",
    "        axes[row][col].imshow(sources_test_01[i])\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3,3, figsize=(8,8))\n",
    "i = 0\n",
    "for row in range(3):\n",
    "    for col in range(3):\n",
    "        norm = ImageNormalize(decoded_imgs_01[i], interval=ZScaleInterval())\n",
    "        axes[row][col].imshow(decoded_imgs_01[i], norm=norm)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3,3, figsize=(8,8))\n",
    "i = 0\n",
    "for row in range(3):\n",
    "    for col in range(3):\n",
    "        norm = ImageNormalize(sources_test_keras[i], interval=ZScaleInterval())\n",
    "        axes[row][col].imshow(sources_test_keras[i])\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3,3, figsize=(8,8))\n",
    "i = 0\n",
    "for row in range(3):\n",
    "    for col in range(3):\n",
    "        norm = ImageNormalize(decoded_imgs_keras[i], interval=ZScaleInterval())\n",
    "        axes[row][col].imshow(decoded_imgs_keras[i], norm=norm)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now multi-channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use first 25000 cutouts for training and remaining for testing\n",
    "sources_train = sources_multi[:25000]\n",
    "sources_test = sources_multi[25000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_multi = Autoencoder((sources_multi.shape[1], sources_multi.shape[2], 4))\n",
    "autoencoder_multi.compile(optimizer='adam', loss=keras.losses.MeanSquaredError())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/fit/Multi\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "autoencoder_multi.fit(sources_train, sources_train, epochs=25, validation_split=0.2, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs_cfis = autoencoder_multi.encoder(sources_test).numpy()\n",
    "decoded_imgs_cfis = autoencoder_multi.decoder(encoded_imgs_cfis).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,2, figsize=(8,8))\n",
    "i = 0\n",
    "for row in range(2):\n",
    "    for col in range(2):\n",
    "        norm = ImageNormalize(sources_train[0,:,:,i], interval=ZScaleInterval())\n",
    "        axes[row][col].imshow(sources_train[0,:,:,i])\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,2, figsize=(8,8))\n",
    "i = 0\n",
    "for row in range(2):\n",
    "    for col in range(2):\n",
    "        norm = ImageNormalize(decoded_imgs_cfis[0,:,:,i], interval=ZScaleInterval())\n",
    "        axes[row][col].imshow(decoded_imgs_cfis[0,:,:,i], norm=norm)\n",
    "        i += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
