{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.nddata.utils import Cutout2D\n",
    "from astropy.io import fits\n",
    "from astropy import table\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.visualization import (ZScaleInterval, ImageNormalize)\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"/home/eyvorch9/projects/rrg-kyi/astro/cfis/W3/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_list = open(image_dir + \"tiles.list\", \"r\")\n",
    "for tile in tile_list.readlines():\n",
    "    print(tile[:-1])\n",
    "tile_list.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only use tiles with all five channels\n",
    "\n",
    "tile_list = open(image_dir + \"tiles.list\", \"r\")\n",
    "\n",
    "u_images = []\n",
    "u_weights = []\n",
    "g_images = []\n",
    "g_weights = []\n",
    "r_images = []\n",
    "r_weights = []\n",
    "i_images= []\n",
    "i_weights = []\n",
    "z_images = []\n",
    "z_weights = []\n",
    "cats = []\n",
    "\n",
    "for tile in tile_list:\n",
    "    tile = tile[:-1] # Remove new line character\n",
    "    channels = tile.split(\" \")\n",
    "    if len(channels) == 5: # Order is u,g,r,i,z\n",
    "        u_images.append(image_dir + channels[0] + \".fits\")\n",
    "        u_weights.append(image_dir + channels[0] + \".weight.fits.fz\")\n",
    "        g_images.append(image_dir + channels[1] + \".fits\")\n",
    "        g_weights.append(image_dir + channels[1] + \".wt.fits\")\n",
    "        r_images.append(image_dir + channels[2] + \".fits\")\n",
    "        r_weights.append(image_dir + channels[2] + \".weight.fits.fz\")\n",
    "        i_images.append(image_dir + channels[3] + \".fits\")\n",
    "        i_weights.append(image_dir + channels[3] + \".wt.fits\")\n",
    "        z_images.append(image_dir + channels[4] + \".fits\")\n",
    "        z_weights.append(image_dir + channels[4] + \".wt.fits\")\n",
    "        cats.append(image_dir + channels[2] + \".cat\")\n",
    "tile_list.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(u_images))\n",
    "print(len(u_weights))\n",
    "print(len(g_images))\n",
    "print(len(g_weights))\n",
    "print(len(r_images))\n",
    "print(len(r_weights))\n",
    "print(len(i_images))\n",
    "print(len(i_weights))\n",
    "print(len(z_images))\n",
    "print(len(z_weights))\n",
    "print(len(cats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only use 25000 cutouts to reduce tensor size\n",
    "lim = 25000\n",
    "size = 32\n",
    "sources = np.zeros((lim, size, size, 5)) # Order of channels is u,g,r,i,z. Normalized data.\n",
    "#weights = np.zeros((lim, size, size, 5))\n",
    "n = 0\n",
    "for i in range(len(cats)):\n",
    "    u_image = fits.open(u_images[i], memmap=True)\n",
    "    #u_weight = fits.open(u_weights[i], memmap=True)\n",
    "    g_image = fits.open(g_images[i], memmap=True)\n",
    "    #g_weight = fits.open(g_weights[i], memmap=True)\n",
    "    r_image = fits.open(r_images[i], memmap=True)\n",
    "    #r_weight = fits.open(r_weights[i], memmap=True)\n",
    "    i_image = fits.open(i_images[i], memmap=True)\n",
    "    #i_weight = fits.open(i_weights[i], memmap=True)\n",
    "    z_image = fits.open(z_images[i], memmap=True)\n",
    "    #z_weight = fits.open(z_weights[i], memmap=True)\n",
    "    \n",
    "    cat = table.Table.read(cats[i], format=\"ascii.sextractor\")\n",
    "    for (x, y) in zip(cat[\"X_IMAGE\"], cat[\"Y_IMAGE\"]):\n",
    "        g_cutout = Cutout2D(g_image[0].data, (x, y), size, mode=\"partial\", fill_value=0).data\n",
    "        if len(g_cutout[np.isnan(g_cutout)]) > 0.05*len(g_cutout)**2:\n",
    "            continue\n",
    "        i_cutout = Cutout2D(i_image[0].data, (x, y), size, mode=\"partial\", fill_value=0).data\n",
    "        if len(i_cutout[np.isnan(i_cutout)]) > 0.05*len(i_cutout)**2:\n",
    "            continue\n",
    "        z_cutout = Cutout2D(z_image[0].data, (x, y), size, mode=\"partial\", fill_value=0).data\n",
    "        if len(z_cutout[np.isnan(z_cutout)]) > 0.05*len(z_cutout)**2:\n",
    "            continue\n",
    "        \n",
    "        r_cutout = Cutout2D(r_image[0].data, (x, y), size, mode=\"partial\", fill_value=0).data\n",
    "        #r_weight_cutout = Cutout2D(r_weight[1].data, (x, y), size, mode=\"partial\", fill_value=0).data\n",
    "        u_cutout = Cutout2D(u_image[0].data, (x, y), size, mode=\"partial\", fill_value=0).data\n",
    "        #u_weight_cutout = Cutout2D(u_weight[1].data, (x, y), size, mode=\"partial\", fill_value=0).data\n",
    "        #g_weight_cutout = Cutout2D(g_weight[0].data, (x, y), size, mode=\"partial\", fill_value=0).data\n",
    "        #i_weight_cutout = Cutout2D(i_weight[0].data, (x, y), size, mode=\"partial\", fill_value=0).data\n",
    "        #z_weight_cutout = Cutout2D(z_weight[0].data, (x, y), size, mode=\"partial\", fill_value=0).data\n",
    "\n",
    "        g_cutout[np.isnan(g_cutout)] = 0\n",
    "        #g_weight_cutout[np.isnan(g_weight_cutout)] = 0\n",
    "        i_cutout[np.isnan(i_cutout)] = 0\n",
    "        #i_weight_cutout[np.isnan(i_weight_cutout)] = 0\n",
    "        z_cutout[np.isnan(z_cutout)] = 0\n",
    "        #z_weight_cutout[np.isnan(z_weight_cutout)] = 0\n",
    "        \n",
    "        #u_lower = np.percentile(u_cutout, 1)\n",
    "        #u_upper = np.percentile(u_cutout, 99)\n",
    "        g_lower = np.percentile(g_cutout, 1)\n",
    "        g_upper = np.percentile(g_cutout, 99)\n",
    "        i_lower = np.percentile(i_cutout, 1)\n",
    "        i_upper = np.percentile(i_cutout, 99)\n",
    "        r_lower = np.percentile(r_cutout, 1)\n",
    "        r_upper = np.percentile(r_cutout, 99)\n",
    "        z_lower = np.percentile(z_cutout, 1)\n",
    "        z_upper = np.percentile(z_cutout, 99)\n",
    "                \n",
    "        #sources[n,:,:,0] = (u_cutout - u_lower) / (u_upper - u_lower)\n",
    "        #weights[n,:,:,0] = (u_weight_cutout - np.min(u_weight_cutout)) / (np.max(u_cutout) - np.min(u_cutout))\n",
    "        sources[n,:,:,0] = 0\n",
    "        sources[n,:,:,1] = (g_cutout - g_lower) / (g_upper - g_lower)\n",
    "        #weights[n,:,:,1] = (g_weight_cutout - np.min(g_weight_cutout)) / (np.max(g_cutout) - np.min(g_cutout))\n",
    "        sources[n,:,:,2] = (r_cutout - r_lower) / (r_upper - r_lower)\n",
    "        #weights[n,:,:,2] = (r_weight_cutout - np.min(r_weight_cutout)) / (np.max(r_cutout) - np.min(r_cutout))\n",
    "        sources[n,:,:,3] = (i_cutout - i_lower) / (i_upper - i_lower)\n",
    "        #weights[n,:,:,3] = (i_weight_cutout - np.min(i_weight_cutout)) / (np.max(i_cutout) - np.min(i_cutout))\n",
    "        sources[n,:,:,4] = (z_cutout - z_lower) / (z_upper - z_lower)\n",
    "        #weights[n,:,:,4] = (z_weight_cutout - np.min(z_weight_cutout)) / (np.max(z_cutout) - np.min(z_cutout))\n",
    "        \n",
    "        #sources[np.isnan(sources)] = 0 # Due to division by 0\n",
    "        #weights[np.isnan(weights)] = 0\n",
    "        n += 1\n",
    "        if n == lim:\n",
    "            break\n",
    "    u_image.close()\n",
    "    #u_weight.close()\n",
    "    g_image.close()\n",
    "    #g_weight.close()\n",
    "    r_image.close()\n",
    "    #r_weight.close()\n",
    "    i_image.close()\n",
    "    #i_weight.close()\n",
    "    z_image.close()\n",
    "    #z_weight.close()\n",
    "    if n == lim:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images, start=0):\n",
    "    fig, axes = plt.subplots(3,5, figsize=(12,8))\n",
    "    for row in range(3):\n",
    "        i = 0\n",
    "        for col in range(5):\n",
    "            norm = ImageNormalize(images[start+row,:,:,i])\n",
    "            axes[row][col].imshow(images[start+row,:,:,i], norm=norm)\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = int(0.8*len(sources))\n",
    "sources_train = sources[:threshold]\n",
    "sources_test = sources[threshold:]\n",
    "#weights_train = weights[:threshold]\n",
    "#weights_test = weights[threshold:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_autoencoder1(shape):\n",
    "    input_img = keras.Input(shape=shape)\n",
    "    x = keras.layers.Conv2D(16, kernel_size=3, activation='relu', padding='same')(input_img)\n",
    "    x = keras.layers.MaxPooling2D((2,2), padding='same')(x)\n",
    "    x = keras.layers.Conv2D(32, kernel_size=3, activation='relu', padding='same')(x)\n",
    "    x = keras.layers.MaxPooling2D((2,2), padding='same')(x)\n",
    "    x = keras.layers.Flatten()(x)\n",
    "    x = keras.layers.Dense(128)(x)\n",
    "    encoded = keras.layers.Dense(256)(x)\n",
    "    \n",
    "    x = keras.layers.Reshape((8,8,4))(encoded)\n",
    "    x = keras.layers.UpSampling2D((2,2))(x)\n",
    "    x = keras.layers.Conv2DTranspose(32, kernel_size=3, activation='relu', padding='same')(x)\n",
    "    x = keras.layers.UpSampling2D((2,2))(x)\n",
    "    x = keras.layers.Conv2DTranspose(16, kernel_size=3, activation='relu', padding='same')(x)\n",
    "    decoded = keras.layers.Conv2D(shape[2], (3,3), activation='linear', padding='same')(x)\n",
    "    \n",
    "    return keras.Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder1 = create_autoencoder1((sources.shape[1], sources.shape[2], sources.shape[3]))\n",
    "#opt = keras.optimizers.Adam(learning_rate=0.005)\n",
    "autoencoder1.compile(optimizer=\"adam\", loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history1 = autoencoder1.fit(sources_train, sources_train, batch_size=128, epochs=100, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_curves(history):\n",
    "    plt.plot(history.history[\"loss\"], color=\"g\", label=\"Training\")\n",
    "    plt.plot(history.history[\"val_loss\"], color=\"b\", label=\"Validation\")\n",
    "    plt.title(\"Loss Curves for Training/Validation Sets\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(history1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs1 = autoencoder1.predict(sources_test[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(sources_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(decoded_imgs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_autoencoder2(shape):\n",
    "    input_img = keras.Input(shape=shape)\n",
    "    x = keras.layers.Conv2D(8, kernel_size=3, activation='relu', padding='same')(input_img)\n",
    "    x = keras.layers.MaxPooling2D((2,2), padding='same')(x)\n",
    "    encoded = keras.layers.Conv2D(16, kernel_size=3, activation='relu', padding='same')(x)\n",
    "\n",
    "    x = keras.layers.Conv2DTranspose(16, kernel_size=3, activation='relu', padding='same')(encoded)\n",
    "    x = keras.layers.UpSampling2D((2,2))(x)\n",
    "    x = keras.layers.Conv2DTranspose(8, kernel_size=3, activation='relu', padding='same')(x)\n",
    "    decoded = keras.layers.Conv2D(shape[2], (3,3), activation='linear', padding='same')(x)\n",
    "    \n",
    "    return keras.Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder2 = create_autoencoder2((sources.shape[1], sources.shape[2], sources.shape[3]))\n",
    "autoencoder2.compile(optimizer='adam', loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history2 = autoencoder2.fit(sources_train, sources_train, batch_size=128, epochs=100, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(history2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs2 = autoencoder2.predict(sources_test[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(sources_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(decoded_imgs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEnc(keras.Model):\n",
    "    def __init__(self, input_shape, noise=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.batch_size = 64\n",
    "        self.input_shape = input_shape\n",
    "        self.num_out = 1\n",
    "        self.num_z = 128\n",
    "        self.checkpoint = 1\n",
    "        \n",
    "        self.enc_lr = 1e-6\n",
    "        self.dec_lr = 1e-6\n",
    "        enc_optimizer = keras.optimizers.Adam(lr=self.enc_lr)            \n",
    "        dec_optimizer = keras.optimizers.Adam(lr=self.dec_lr)\n",
    "        \n",
    "        self.inp = keras.layers.Input(input_shape, name='ae_input')\n",
    "        self.Enc = keras.models.Model(self.inp, \\\n",
    "            self.encoder(self.inp)[0], name='encoder')\n",
    "        self.Dec = keras.models.Model(self.inp, \\\n",
    "            self.decoder(tf.concat(self.encoder(self.inp),axis=1)), name='decoder')\n",
    "        \n",
    "        self.Enc.compile(loss=keras.losses.MSE,\\\n",
    "            optimizer=enc_optimizer)\n",
    "        self.Dec.compile(loss=keras.losses.MSE,\\\n",
    "            optimizer=dec_optimizer)\n",
    "\n",
    "    def encoder(self,y):\n",
    "        base_model = keras.applications.ResNet50(include_top=False, weights=None,\\\n",
    "            input_shape=self.input_shape)\n",
    "        base_model.trainable = True\n",
    "        model_out = base_model(y, training=True)\n",
    "        model_out = keras.layers.GlobalAveragePooling2D()(model_out)\n",
    "        \n",
    "        x = keras.layers.Dense(512,activation=keras.layers.LeakyReLU(alpha=0.1))(model_out)\n",
    "        x = keras.layers.Dense(256,activation=keras.layers.LeakyReLU(alpha=0.1))(x)\n",
    "\n",
    "        #can probably do this in one layer\n",
    "        x_out = keras.layers.Dense(self.num_out)(x)\n",
    "        z_out = keras.layers.Dense(self.num_z)(x)\n",
    "        \n",
    "        return x_out,z_out \n",
    "\n",
    "    def decoder(self,z):\n",
    "        #TODO this decoder was made in a rush and will be changed in future\n",
    "        #These layers assume a shape (32x32x5)\n",
    "\n",
    "        y = keras.layers.Dense(self.num_z + self.num_out)(z)\n",
    "        y = keras.layers.Dense(256,activation=keras.layers.LeakyReLU(alpha=0.1))(y)\n",
    "        y = keras.layers.Dense(512,activation=keras.layers.LeakyReLU(alpha=0.1))(y)\n",
    "        y = keras.layers.Dense(8192)(y)\n",
    "        y = keras.layers.Reshape([2,2,2048])(y)\n",
    "\n",
    "        y = keras.layers.Conv2DTranspose(512,3)(y)\n",
    "        y = keras.layers.Conv2DTranspose(128,5)(y)\n",
    "        y = keras.layers.Conv2DTranspose(64,9)(y)\n",
    "        y = keras.layers.Conv2DTranspose(4,17)(y)\n",
    "\n",
    "        return y\n",
    "\n",
    "\n",
    "    def train(self, x_train, y_train, x_test, y_test, epochs):\n",
    "        \n",
    "        N = int(len(x_train)/self.batch_size)\n",
    "\n",
    "        reglosses = np.zeros(self.checkpoint)\n",
    "        reconlosses = np.zeros(self.checkpoint)\n",
    "\n",
    "        it = 0               \n",
    "        while it < epochs:    \n",
    "            x_train, y_train = shuffle(x_train,y_train)\n",
    "            \n",
    "            for j in range(N):\n",
    "                x_true = x_train[j*self.batch_size: (j+1)*self.batch_size]\n",
    "                y_true = y_train[j*self.batch_size: (j+1)*self.batch_size]\n",
    "       \n",
    "                #Im working on another version where both are trained simulateously\n",
    "                enc_loss = self.Enc.train_on_batch(x_true, y_true)\n",
    "                dec_loss = self.Dec.train_on_batch(x_true, x_true)\n",
    "            \n",
    "                reglosses[it%self.checkpoint] = enc_loss[0]\n",
    "                reconlosses[it%self.checkpoint] = dec_loss\n",
    "\n",
    "            if it % self.checkpoint == 0:\n",
    "                ##TODO add correct saving and validation tests to checkpoints\n",
    "                self.curr_epoch += self.checkpoint\n",
    "                \n",
    "                print('Iterations %d' % self.curr_epoch)\n",
    "                print('Regression Loss %f' % np.mean(reglosses))\n",
    "                print('Reconstruction Loss %f' % np.mean(reconlosses))\n",
    "\n",
    "                \n",
    "\n",
    "            it += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
